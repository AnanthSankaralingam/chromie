import { useState, useRef, useEffect } from "react"

export function useChatState(projectId, hasGeneratedCodeProp) {
  const [inputMessage, setInputMessage] = useState("")
  const [messages, setMessages] = useState([
    {
      role: "assistant",
      content: "hi! i'm **chromie**, your chrome extension assistant. tell me what you'd like in your extension.",
    },
  ])
  const [isGenerating, setIsGenerating] = useState(false)
  const [hasGeneratedCode, setHasGeneratedCode] = useState(false)

  // Use prop if provided, otherwise use internal state
  const effectiveHasGeneratedCode = hasGeneratedCodeProp !== undefined ? hasGeneratedCodeProp : hasGeneratedCode

  // Modal states
  const [showTokenLimitModal, setShowTokenLimitModal] = useState(false)

  // Refs for tracking state
  const autoGeneratedRef = useRef(false)
  const currentRequestRef = useRef(null)
  const lastUrlSelectionRef = useRef(null)
  const currentAssistantMessageRef = useRef(null)
  const thinkingBufferRef = useRef("")
  const thinkingMessageIndexRef = useRef(null)
  const explanationBufferRef = useRef("")
  const sentGeneratingMessageRef = useRef(false)
  const filesSavedRef = useRef(false)
  const doneReceivedRef = useRef(false)
  const hasShownStartMessageRef = useRef(false)

  // Token usage
  const [conversationTokenTotal, setConversationTokenTotal] = useState(0)
  const [typingCancelSignal, setTypingCancelSignal] = useState(0)

  // Model thinking panel state
  const [isModelThinkingOpen, setIsModelThinkingOpen] = useState(false)
  const [modelThinkingFull, setModelThinkingFull] = useState("")
  const [modelThinkingDisplay, setModelThinkingDisplay] = useState("")
  const [isGenerationComplete, setIsGenerationComplete] = useState(false)
  const thinkingTimerRef = useRef(null)
  const thinkingTokensRef = useRef([])
  const thinkingIdxRef = useRef(0)
  const thinkingChunkCountRef = useRef(0)

  // Planning progress state
  const [planningProgress, setPlanningProgress] = useState(null)
  const [currentPlanningPhase, setCurrentPlanningPhase] = useState(null)

  // Track when actual code generation (not planning) starts
  const [isActuallyGeneratingCode, setIsActuallyGeneratingCode] = useState(false)

  // Reset conversation state on project change
  useEffect(() => {
    setConversationTokenTotal(0)
  }, [projectId])

  // Adaptive typing for model thinking panel
  useEffect(() => {
    if (!modelThinkingFull) return

    const tokenize = (text) => {
      const sentences = text.split(/(?<=[.!?])\s+/)
      const result = []
      for (const s of sentences) {
        const parts = s.split(/(\s+)/)
        for (const p of parts) { if (p) result.push(p) }
        result.push(" ")
      }
      return result
    }

    thinkingTokensRef.current = tokenize(modelThinkingFull)
    const total = thinkingTokensRef.current.length

    const step = () => {
      const base = total < 40 ? 2 : total < 120 ? 3 : total < 250 ? 5 : 8
      const next = Math.min(thinkingIdxRef.current + base, total)
      const slice = thinkingTokensRef.current.slice(0, next).join("")
      thinkingIdxRef.current = next
      setModelThinkingDisplay(slice)
      if (next < total) {
        const delay = total < 40 ? 28 : total < 120 ? 18 : total < 250 ? 12 : 9
        thinkingTimerRef.current = setTimeout(step, delay)
      }
    }

    if (thinkingTimerRef.current) clearTimeout(thinkingTimerRef.current)
    thinkingTimerRef.current = setTimeout(step, 8)

    return () => { if (thinkingTimerRef.current) clearTimeout(thinkingTimerRef.current) }
  }, [modelThinkingFull])

  const resetStreamState = (resetStartMessage = false) => {
    currentAssistantMessageRef.current = null
    thinkingBufferRef.current = ""
    thinkingMessageIndexRef.current = null
    explanationBufferRef.current = ""
    sentGeneratingMessageRef.current = false
    setIsModelThinkingOpen(false)
    setModelThinkingFull("")
    setModelThinkingDisplay("")
    setIsGenerationComplete(false)
    thinkingTokensRef.current = []
    thinkingIdxRef.current = 0
    thinkingChunkCountRef.current = 0
    if (thinkingTimerRef.current) {
      clearTimeout(thinkingTimerRef.current)
      thinkingTimerRef.current = null
    }
    setPlanningProgress(null)
    setCurrentPlanningPhase(null)
    setIsActuallyGeneratingCode(false)
    filesSavedRef.current = false
    doneReceivedRef.current = false
    // Only reset start message flag for new generations, not continuations
    if (resetStartMessage) {
      hasShownStartMessageRef.current = false
    }
  }

  return {
    // State
    inputMessage,
    setInputMessage,
    messages,
    setMessages,
    isGenerating,
    setIsGenerating,
    hasGeneratedCode,
    setHasGeneratedCode,
    effectiveHasGeneratedCode,

    // Modal states
    showTokenLimitModal,
    setShowTokenLimitModal,

    // Refs
    autoGeneratedRef,
    currentRequestRef,
    lastUrlSelectionRef,
    currentAssistantMessageRef,
    thinkingBufferRef,
    thinkingMessageIndexRef,
    explanationBufferRef,
    sentGeneratingMessageRef,
    filesSavedRef,
    doneReceivedRef,
    hasShownStartMessageRef,

    // Token usage
    conversationTokenTotal,
    setConversationTokenTotal,
    typingCancelSignal,
    setTypingCancelSignal,

    // Model thinking
    isModelThinkingOpen,
    setIsModelThinkingOpen,
    modelThinkingFull,
    setModelThinkingFull,
    modelThinkingDisplay,
    setModelThinkingDisplay,
    isGenerationComplete,
    setIsGenerationComplete,
    thinkingTimerRef,
    thinkingTokensRef,
    thinkingIdxRef,
    thinkingChunkCountRef,

    // Planning progress
    planningProgress,
    setPlanningProgress,
    currentPlanningPhase,
    setCurrentPlanningPhase,

    // Code generation state
    isActuallyGeneratingCode,
    setIsActuallyGeneratingCode,

    // Helpers
    resetStreamState,
  }
}
