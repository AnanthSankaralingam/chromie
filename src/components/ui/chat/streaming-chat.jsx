"use client"

import { useState, useRef, useEffect } from "react"
import { Button } from "@/components/ui/button"
import { Textarea } from "@/components/ui/forms-and-input/textarea"
import { Send, Loader2, ChevronDown, ChevronRight, FileCode } from "lucide-react"
import { AIInputWithSearch } from "@/components/ui/ai-input-with-search"
import { REQUEST_TYPES } from "@/lib/prompts/request-types"
import ModalUrlPrompt from "@/components/ui/modals/modal-url-prompt"
import ModalApiPrompt from "@/components/ui/modals/modal-api-prompt"
import TokenUsageAlert from "@/components/ui/modals/token-usage-alert"
import ChatMessage from "@/components/ui/chat/chat-message"
import { ChatMessageList } from "@/components/ui/chat-message-list"
import { ChatBubble, ChatBubbleMessage, ChatBubbleAvatar } from "@/components/ui/chat-bubble"
import { Conversation, ConversationContent, ConversationScrollButton } from "@/components/ui/conversation"

export default function StreamingChat({
  projectId,
  projectName,
  autoGeneratePrompt,
  onAutoGenerateComplete,
  onCodeGenerated,
  onGenerationStart,
  onGenerationEnd,
  onOpenCanvas,
  hasGeneratedCode: hasGeneratedCodeProp,
  isCanvasOpen,
  isProjectReady,
  isOnboardingModalOpen,
  modelOverride
}) {
  const [inputMessage, setInputMessage] = useState("")
  const [messages, setMessages] = useState([
    {
      role: "assistant",
      content: "hi! i'm **chromie**, your chrome extension assistant. tell me what you'd like in your extension.",
    },
  ])
  const [isGenerating, setIsGenerating] = useState(false)
  const [hasGeneratedCode, setHasGeneratedCode] = useState(false)
  
  // Use prop if provided, otherwise use internal state
  const effectiveHasGeneratedCode = hasGeneratedCodeProp !== undefined ? hasGeneratedCodeProp : hasGeneratedCode
  const [urlPromptData, setUrlPromptData] = useState(null)
  const [showUrlPrompt, setShowUrlPrompt] = useState(false)
  const [apiPromptData, setApiPromptData] = useState(null)
  const [showApiPrompt, setShowApiPrompt] = useState(false)
  const [showTokenLimitModal, setShowTokenLimitModal] = useState(false)
  // Queue for modals that need to be shown after onboarding closes
  const [pendingUrlPrompt, setPendingUrlPrompt] = useState(null)
  const [pendingApiPrompt, setPendingApiPrompt] = useState(null)
  const autoGeneratedRef = useRef(false)
  const currentRequestRef = useRef(null)
  const lastUrlSelectionRef = useRef(null) // Track last user URL or skip choice for follow-up prompts
  const currentAssistantMessageRef = useRef(null) // Track current streaming message
  const thinkingBufferRef = useRef("") // Buffer for accumulating thinking content
  const thinkingMessageIndexRef = useRef(null) // Track the thinking message index
  const explanationBufferRef = useRef("") // Buffer for accumulating final explanation tokens
  const sentGeneratingMessageRef = useRef(false) // Ensure generating message shows only once
  const previousResponseIdRef = useRef(null)
  const [conversationTokenTotal, setConversationTokenTotal] = useState(0)
  const [typingCancelSignal, setTypingCancelSignal] = useState(0)
  // Gemini thinking panel state (per request)
  const [isModelThinkingOpen, setIsModelThinkingOpen] = useState(false)
  const [modelThinkingFull, setModelThinkingFull] = useState("")
  const [modelThinkingDisplay, setModelThinkingDisplay] = useState("")
  const [isGenerationComplete, setIsGenerationComplete] = useState(false)
  const thinkingTimerRef = useRef(null)
  const thinkingTokensRef = useRef([])
  const thinkingIdxRef = useRef(0)
  const thinkingChunkCountRef = useRef(0)
  // Planning progress state
  const [planningProgress, setPlanningProgress] = useState(null)
  const [currentPlanningPhase, setCurrentPlanningPhase] = useState(null)
  // Track whether files have been saved before showing completion modal
  const filesSavedRef = useRef(false)
  const doneReceivedRef = useRef(false)

  // Reset local-only conversation state on project change (navigation/refresh)
  useEffect(() => {
    previousResponseIdRef.current = null
    setConversationTokenTotal(0)
  }, [projectId])

  // Adaptive typing for model thinking panel (slightly larger batches)
  useEffect(() => {
    if (!modelThinkingFull) return
    // Build token list on new text arrival
    const tokenize = (text) => {
      const sentences = text.split(/(?<=[.!?])\s+/)
      const result = []
      for (const s of sentences) {
        const parts = s.split(/(\s+)/)
        for (const p of parts) { if (p) result.push(p) }
        result.push(" ")
      }
      return result
    }
    thinkingTokensRef.current = tokenize(modelThinkingFull)
    const total = thinkingTokensRef.current.length
    const step = () => {
      const base = total < 40 ? 2 : total < 120 ? 3 : total < 250 ? 5 : 8
      const next = Math.min(thinkingIdxRef.current + base, total)
      const slice = thinkingTokensRef.current.slice(0, next).join("")
      thinkingIdxRef.current = next
      setModelThinkingDisplay(slice)
      if (next < total) {
        const delay = total < 40 ? 28 : total < 120 ? 18 : total < 250 ? 12 : 9
        thinkingTimerRef.current = setTimeout(step, delay)
      }
    }
    if (thinkingTimerRef.current) clearTimeout(thinkingTimerRef.current)
    thinkingTimerRef.current = setTimeout(step, 8)
    return () => { if (thinkingTimerRef.current) clearTimeout(thinkingTimerRef.current) }
  }, [modelThinkingFull])

  useEffect(() => {
    // Start auto-generation immediately - onboarding can happen in parallel
    if (autoGeneratePrompt && isProjectReady && !hasGeneratedCode && !isGenerating && !autoGeneratedRef.current) {
      autoGeneratedRef.current = true // Prevent duplicate auto-generation
      setInputMessage(autoGeneratePrompt)

      // Add the user message immediately
      const userMessage = {
        role: "user",
        content: autoGeneratePrompt,
      }
      setMessages((prev) => [...prev, userMessage])

      // Start the generation process - input modals will be deferred if onboarding is open
      startGeneration(autoGeneratePrompt, true) // true indicates this is auto-generation
    }
  }, [autoGeneratePrompt, isProjectReady, hasGeneratedCode, isGenerating])

  // Watch for onboarding close and show pending modals
  useEffect(() => {
    // Only trigger when onboarding closes (was open, now closed)
    if (!isOnboardingModalOpen) {
      // Check for pending URL prompt
      if (pendingUrlPrompt) {
        console.log('âœ… Onboarding closed - showing pending URL prompt modal')
        setUrlPromptData(pendingUrlPrompt)
        setShowUrlPrompt(true)
        setPendingUrlPrompt(null) // Clear the pending state
      }
      // Check for pending API prompt
      else if (pendingApiPrompt) {
        console.log('âœ… Onboarding closed - showing pending API prompt modal')
        setApiPromptData(pendingApiPrompt)
        setShowApiPrompt(true)
        setPendingApiPrompt(null) // Clear the pending state
      }
    }
  }, [isOnboardingModalOpen, pendingUrlPrompt, pendingApiPrompt])

  const startGeneration = async (prompt, isAutoGeneration = false) => {
    if (isGenerating) {
      console.log('âš ï¸ [StreamingChat] startGeneration called but already generating - ignoring')
      return
    }
    
    console.log('ðŸš€ [StreamingChat] Starting generation:', { prompt: prompt?.substring(0, 50), isAutoGeneration })
    // Reset URL selection context at the start of a brand new generation
    lastUrlSelectionRef.current = null
    setIsGenerating(true)
    
    // Reset current assistant message tracking
    currentAssistantMessageRef.current = null
    thinkingBufferRef.current = ""
    thinkingMessageIndexRef.current = null
    explanationBufferRef.current = ""
    sentGeneratingMessageRef.current = false
    // Reset model thinking panel per request
    setIsModelThinkingOpen(false)
    setModelThinkingFull("")
    setModelThinkingDisplay("")
    setIsGenerationComplete(false)
    thinkingTokensRef.current = []
    thinkingIdxRef.current = 0
    thinkingChunkCountRef.current = 0
    if (thinkingTimerRef.current) { clearTimeout(thinkingTimerRef.current); thinkingTimerRef.current = null }
    // Reset planning progress state
    setPlanningProgress(null)
    setCurrentPlanningPhase(null)
    // Reset file save tracking
    filesSavedRef.current = false
    doneReceivedRef.current = false

    if (onGenerationStart) {
      onGenerationStart()
    }

    try {
      // Force refresh hasGeneratedCode from Supabase before determining request type
      let currentHasGeneratedCode = hasGeneratedCode
      if (projectId) {
        try {
          const response = await fetch(`/api/projects/${projectId}/has-generated-code`)
          if (response.ok) {
            const data = await response.json()
            currentHasGeneratedCode = data.hasGeneratedCode
            if (data.hasGeneratedCode !== hasGeneratedCode) {
              setHasGeneratedCode(data.hasGeneratedCode)
            }
          }
        } catch (error) {
          console.error('Error refreshing hasGeneratedCode:', error)
        }
      }
      
      const requestType = currentHasGeneratedCode ? REQUEST_TYPES.ADD_TO_EXISTING : REQUEST_TYPES.NEW_EXTENSION
      const hasPrev = Boolean(previousResponseIdRef.current)
      const pathUsed = requestType === REQUEST_TYPES.ADD_TO_EXISTING && hasPrev ? 'responses_api' : 'manual_file_context'

      // Start streaming response
      const response = await fetch("/api/generate/stream", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          prompt: prompt,
          projectId,
          requestType: requestType,
          previousResponseId: previousResponseIdRef.current,
          conversationTokenTotal,
          modelOverride
        }),
      })

      if (!response.ok) {
        // Check if it's a token limit error (403 with specific structure)
        if (response.status === 403) {
          try {
            const errorData = await response.json()
            if (errorData.details?.resourceType === 'tokens') {
              // Show modal for token limit errors
              setShowTokenLimitModal(true)
              setIsGenerating(false)
              if (onGenerationEnd) {
                onGenerationEnd()
              }
              return
            }
          } catch (e) {
            // If we can't parse the response, fall through to generic error
          }
        }
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const reader = response.body.getReader()
      const decoder = new TextDecoder()
      let buffer = ""

      while (true) {
        const { done, value } = await reader.read()
        if (done) break

        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ""

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6))

              // Helper function to add new assistant message
              const addNewAssistantMessage = (content) => {
                const newMessage = {
                  role: "assistant",
                  content: content
                }
                setMessages(prev => [...prev, newMessage])
              }

              switch (data.type) {
                case "thinking_chunk":
                case "thinking":
                  // Append Gemini thinking text to model thinking panel
                  if (typeof data.content === 'string' && data.content.length > 0) {
                    thinkingChunkCountRef.current += 1
                    setModelThinkingFull(prev => {
                      const newContent = prev + data.content
                      return newContent
                    })
                    // Keep thinking panel collapsed by default; user can expand
                  }
                  break
                case "planning_progress":
                  // Handle planning progress updates
                  if (data.phase && data.content) {
                    setCurrentPlanningPhase(data.phase)
                    setPlanningProgress(data.content)
                  }
                  break
                case "start":
                  // Only add the start message if we haven't generated code yet
                  if (!hasGeneratedCode) {
                    addNewAssistantMessage("Starting to analyze your request...")
                  }
                  break
                case "token_usage":
                  if (typeof data.total === 'number') {
                    setConversationTokenTotal(data.total)
                  }
                  break
                case "usage_summary":
                  // Usage data is tracked server-side but not displayed to users
                  break
                case "context_window":
                  addNewAssistantMessage('Context limit reached. Please start a new conversation.')
                  if (typeof data.total === 'number') {
                    setConversationTokenTotal(data.total)
                  }
                  // Do not continue processing further
                  break
                case "response_id":
                  previousResponseIdRef.current = data.id
                  if (typeof data.tokensUsedThisRequest === 'number') {
                    const nextTotal = (conversationTokenTotal || 0) + data.tokensUsedThisRequest
                    setConversationTokenTotal(nextTotal)
                  }
                  break

                // Ignore intermediate status noise
                case "analyzing":
                case "analysis_complete":
                case "fetching_apis":
                case "apis_ready":
                case "scraping":
                case "scraping_complete":
                case "scraping_skipped":
                case "context_ready":
                case "generation_starting":
                  break

                case "phase":
                  // Do not render phase updates to keep UI clean
                  break

                case "explanation":
                  // Buffer explanation tokens; emit once on done
                  if (data.content) {
                    explanationBufferRef.current += data.content
                  }
                  break

                case "generating_code":
                  break

                case "code":
                  // If backend supplies file path info, auto-select in editor via global event
                  try {
                    const filePath = data.file_path || data.path || data.file || null
                    if (filePath && typeof window !== 'undefined') {
                      const evt = new CustomEvent('editor:selectFile', { detail: { file_path: String(filePath) } })
                      window.dispatchEvent(evt)
                    }
                  } catch (_) {}
                  break
                case "files_saved":
                case "generation_complete":
                  // Mark that files have been saved
                  filesSavedRef.current = true
                  // On save or completion, try to focus manifest.json after a short delay
                  try {
                    if (typeof window !== 'undefined') {
                      setTimeout(() => {
                        const evt = new CustomEvent('editor:focusManifest')
                        window.dispatchEvent(evt)
                      }, 200)
                    }
                  } catch (_) {}
                  // If done was already received, trigger onCodeGenerated now
                  if (doneReceivedRef.current && onCodeGenerated) {
                    onCodeGenerated({ success: true })
                    doneReceivedRef.current = false
                    filesSavedRef.current = false
                  }
                  break

                case "requires_url":
                  // Handle URL requirement
                  console.log('ðŸ“‹ Received requires_url signal:', data)
                  console.log('ðŸ“Š Has analysisData:', !!data.analysisData)
                  if (data.analysisData) {
                    console.log('ðŸ“Š analysisData structure:', {
                      hasRequirements: !!data.analysisData.requirements,
                      hasTokenUsage: !!data.analysisData.tokenUsage
                    })
                  } else {
                    console.warn('âš ï¸ requires_url event missing analysisData! This will cause re-planning.')
                  }
                  addNewAssistantMessage("I need to analyze a specific website to build this extension properly. Let me get that information from you...")

                  // Store the current request info for URL continuation
                  currentRequestRef.current = {
                    prompt: prompt,
                    requestType: requestType,
                    projectId: projectId,
                    // Preserve analysis data so we can resume without re-planning
                    analysisData: data.analysisData
                  }
                  console.log('ðŸ’¾ Stored currentRequestRef with analysisData:', !!currentRequestRef.current.analysisData)

                  const urlModalData = {
                    data: {
                      requiresUrl: true,
                      message: data.content || "This extension would benefit from analyzing specific website structure. Please choose how you'd like to proceed.",
                      detectedSites: data.detectedSites || [],
                      detectedUrls: data.detectedUrls || [],
                      featureRequest: prompt,
                      requestType: requestType
                    },
                    originalPrompt: prompt
                  }

                  // If onboarding is open, queue the modal to show after onboarding closes
                  if (isOnboardingModalOpen) {
                    console.log('â³ Onboarding is open - queueing URL prompt modal')
                    setPendingUrlPrompt(urlModalData)
                  } else {
                    // Show modal immediately if onboarding is closed
                    console.log('âœ… Showing URL prompt modal immediately')
                    setUrlPromptData(urlModalData)
                    setShowUrlPrompt(true)
                  }
                  break

                case "requires_api":
                  // Handle API requirement
                  console.log('ðŸ”Œ Received requires_api event:', {
                    suggestedAPIs: data.suggestedAPIs,
                    content: data.content,
                    hasAnalysisData: !!data.analysisData
                  })
                  addNewAssistantMessage("This extension looks like it might need external APIs. Let me get endpoint details...")

                  // Store the current request info for API continuation
                  currentRequestRef.current = {
                    prompt: prompt,
                    requestType: requestType,
                    projectId: projectId,
                    analysisData: data.analysisData
                  }

                  const apiModalData = {
                    data: {
                      suggestedAPIs: data.suggestedAPIs || [],
                      message: data.content || "This extension looks like it might need external API endpoints. Please configure them or choose to skip."
                    },
                    originalPrompt: prompt
                  }

                  console.log('ðŸ”Œ API Modal Data prepared:', {
                    suggestedAPIsCount: apiModalData.data.suggestedAPIs.length,
                    hasMessage: !!apiModalData.data.message,
                    isOnboardingOpen: isOnboardingModalOpen
                  })

                  // If onboarding is open, queue the modal to show after onboarding closes
                  if (isOnboardingModalOpen) {
                    console.log('â³ Onboarding is open - queueing API prompt modal')
                    setPendingApiPrompt(apiModalData)
                  } else {
                    // Show modal immediately if onboarding is closed
                    console.log('âœ… Showing API prompt modal immediately')
                    setApiPromptData(apiModalData)
                    setShowApiPrompt(true)
                  }
                  break

                case "error":
                  addNewAssistantMessage("I encountered an error: " + data.content + "\n\nPlease try again or let me know if you need help with something else.")
                  break

                case "done":
                  // Mark that done was received
                  doneReceivedRef.current = true
                  
                  // Emit the final explanation once when stream completes
                  if (explanationBufferRef.current.trim()) {
                    addNewAssistantMessage("Here's what I've built for you:\n\n" + explanationBufferRef.current.trim())
                    explanationBufferRef.current = ""
                  }

                  // Mark generation as complete to hide model thoughts
                  setIsGenerationComplete(true)
                  // Clear planning progress when generation is complete
                  setPlanningProgress(null)
                  setCurrentPlanningPhase(null)

                  // Mark that code has been generated
                  if (!hasGeneratedCode) {
                    setHasGeneratedCode(true)
                  }

                  // Only call onCodeGenerated if files have been saved
                  // If files haven't been saved yet, wait for files_saved event
                  if (filesSavedRef.current && onCodeGenerated) {
                    onCodeGenerated({ success: true })
                    doneReceivedRef.current = false
                    filesSavedRef.current = false
                  }

                  // Call auto-generate complete callback if this was an auto-generation
                  if (autoGeneratePrompt && onAutoGenerateComplete) {
                    onAutoGenerateComplete()
                  }
                  
                  // Clear input message after auto-generation completes
                  if (autoGeneratePrompt) {
                    setInputMessage("")
                  }
                  
                  // Reset message tracking
                  currentAssistantMessageRef.current = null
                // Cancel any active typing and render full responses immediately
                setTypingCancelSignal((v) => v + 1)
                  // Also request manifest focus
                  try {
                    if (typeof window !== 'undefined') {
                      const evt = new CustomEvent('editor:focusManifest')
                      window.dispatchEvent(evt)
                    }
                  } catch (_) {}
                  // Flush model thinking panel
                  setModelThinkingDisplay(prev => (modelThinkingFull || prev))
                  if (thinkingTimerRef.current) { clearTimeout(thinkingTimerRef.current); thinkingTimerRef.current = null }
                  break
              }
            } catch (parseError) {
              console.error('Error parsing stream data:', parseError)
            }
          }
        }
      }

    } catch (error) {
      console.error("Error in streaming generation:", error)
      const errorMessage = {
        role: "assistant",
        content: `I encountered an error: ${error.message}\n\nPlease try again or let me know if you need help with something else.`,
      }
      setMessages(prev => [...prev, errorMessage])
    } finally {
      setIsGenerating(false)
      currentAssistantMessageRef.current = null
      // Ensure any typing is cancelled on end/error
      setTypingCancelSignal((v) => v + 1)
      
      // Clear input message after auto-generation completes (even on error)
      if (autoGeneratePrompt) {
        setInputMessage("")
      }
      
      if (onGenerationEnd) {
        onGenerationEnd()
      }
    }
  }

  const startGenerationWithUrl = async (prompt, userUrl, requestType, projectId, analysisData = null) => {
    if (isGenerating) return

    console.log('ðŸ”— [startGenerationWithUrl] Starting with URL:', userUrl, 'Has analysisData:', !!analysisData)
    if (analysisData) {
      console.log('â™»ï¸ [startGenerationWithUrl] Reusing previous planning results - will skip orchestrator')
    }

    setIsGenerating(true)

    // Reset current assistant message tracking
    currentAssistantMessageRef.current = null
    thinkingBufferRef.current = ""
    thinkingMessageIndexRef.current = null

    // Reset model thinking panel state for new stream
    setIsModelThinkingOpen(false)
    setModelThinkingFull("")
    setModelThinkingDisplay("")
    setIsGenerationComplete(false)
    thinkingTokensRef.current = []
    thinkingIdxRef.current = 0
    thinkingChunkCountRef.current = 0
    if (thinkingTimerRef.current) {
      clearTimeout(thinkingTimerRef.current)
      thinkingTimerRef.current = null
    }

    // Reset planning progress state
    setPlanningProgress(null)
    setCurrentPlanningPhase(null)
    // Reset file save tracking
    filesSavedRef.current = false
    doneReceivedRef.current = false

    if (onGenerationStart) {
      onGenerationStart()
    }

    try {
      // Start streaming response with URL
      const hasPrev = Boolean(previousResponseIdRef.current)
      const pathUsed = requestType === REQUEST_TYPES.ADD_TO_EXISTING && hasPrev ? 'responses_api' : 'manual_file_context'

      const requestPayload = {
        prompt: prompt,
        projectId: projectId,
        requestType: requestType,
        userProvidedUrl: userUrl,
        skipScraping: false,
        previousResponseId: previousResponseIdRef.current,
        conversationTokenTotal,
        modelOverride,
        // Pass analysis data to preserve planning results
        ...(analysisData && {
          initialRequirementsAnalysis: analysisData.requirements,
          initialPlanningTokenUsage: analysisData.tokenUsage
        })
      }

      console.log('ðŸ“¤ [startGenerationWithUrl] Sending to API:', {
        userProvidedUrl: userUrl,
        skipScraping: false,
        hasInitialRequirementsAnalysis: !!requestPayload.initialRequirementsAnalysis,
        hasInitialPlanningTokenUsage: !!requestPayload.initialPlanningTokenUsage
      })

      const response = await fetch("/api/generate/stream", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify(requestPayload),
      })

      if (!response.ok) {
        // Check if it's a token limit error (403 with specific structure)
        if (response.status === 403) {
          try {
            const errorData = await response.json()
            if (errorData.details?.resourceType === 'tokens') {
              // Show modal for token limit errors
              setShowTokenLimitModal(true)
              setIsGenerating(false)
              if (onGenerationEnd) {
                onGenerationEnd()
              }
              return
            }
          } catch (e) {
            // If we can't parse the response, fall through to generic error
          }
        }
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const reader = response.body.getReader()
      const decoder = new TextDecoder()
      let buffer = ""

      while (true) {
        const { done, value } = await reader.read()
        if (done) break

        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ""

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6))

              // Helper function to add new assistant message
              const addNewAssistantMessage = (content) => {
                const newMessage = {
                  role: "assistant",
                  content: content
                }
                setMessages(prev => [...prev, newMessage])
              }

              switch (data.type) {
                case "thinking_chunk":
                case "thinking":
                  // Append Gemini thinking text to model thinking panel
                  if (typeof data.content === 'string' && data.content.length > 0) {
                    thinkingChunkCountRef.current += 1
                    setModelThinkingFull(prev => {
                      const newContent = prev + data.content
                      return newContent
                    })
                    // Keep thinking panel collapsed by default; user can expand
                  }
                  break
                case "start":
                  // Only add the start message if we haven't generated code yet
                  if (!hasGeneratedCode) {
                    addNewAssistantMessage("Starting to analyze your request...")
                  }
                  break
                case "planning_progress":
                  // Handle planning progress updates
                  if (data.phase && data.content) {
                    setCurrentPlanningPhase(data.phase)
                    setPlanningProgress(data.content)
                  }
                  break
                case "usage_summary":
                  // Usage data is tracked server-side but not displayed to users
                  break

                // Ignore intermediate status noise
                case "analyzing":
                case "analysis_complete":
                case "fetching_apis":
                case "apis_ready":
                case "scraping":
                case "scraping_complete":
                case "scraping_skipped":
                case "context_ready":
                case "generation_starting":
                  break

                case "phase":
                  // Suppress phase updates
                  break

                case "explanation":
                  // Buffer explanation tokens; emit at done
                  if (data.content) {
                    explanationBufferRef.current += data.content
                  }
                  break

                case "generating_code":
                  break

                case "code":
                  break
                case "files_saved":
                case "generation_complete":
                  // Mark that files have been saved
                  filesSavedRef.current = true
                  // If done was already received, trigger onCodeGenerated now
                  if (doneReceivedRef.current && onCodeGenerated) {
                    onCodeGenerated({ success: true })
                    doneReceivedRef.current = false
                    filesSavedRef.current = false
                  }
                  break

                case "requires_url":
                  // This shouldn't happen in URL mode, but handle gracefully
                  addNewAssistantMessage("Continuing with extension generation...")
                  break

                case "requires_api":
                  // Handle API requirement after URL flow
                  addNewAssistantMessage("This extension needs external API details. Let me get those from you...")

                  // Store the current request info for API continuation
                  currentRequestRef.current = {
                    prompt: prompt,
                    requestType: requestType,
                    projectId: projectId,
                    analysisData: data.analysisData
                  }

                  const apiModalDataUrl = {
                    data: {
                      suggestedAPIs: data.suggestedAPIs || [],
                      message: data.content || "This extension needs external API endpoints. Please configure them or choose to skip."
                    },
                    originalPrompt: prompt
                  }

                  // If onboarding is open, queue the modal
                  if (isOnboardingModalOpen) {
                    console.log('â³ Onboarding is open - queueing API prompt modal (URL flow)')
                    setPendingApiPrompt(apiModalDataUrl)
                  } else {
                    console.log('âœ… Showing API prompt modal immediately (URL flow)')
                    setApiPromptData(apiModalDataUrl)
                    setShowApiPrompt(true)
                  }
                  break

                case "error":
                  addNewAssistantMessage("I encountered an error: " + data.content + "\n\nPlease try again or let me know if you need help with something else.")
                  break

                case "done":
                  // Mark that done was received
                  doneReceivedRef.current = true
                  
                  // Emit final explanation once when stream completes
                  if (explanationBufferRef.current.trim()) {
                    addNewAssistantMessage("Here's what I've built for you:\n\n" + explanationBufferRef.current.trim())
                    explanationBufferRef.current = ""
                  }

                  // Mark generation as complete to hide model thoughts
                  setIsGenerationComplete(true)
                  // Clear planning progress when generation is complete
                  setPlanningProgress(null)
                  setCurrentPlanningPhase(null)

                  // Mark that code has been generated
                  if (!hasGeneratedCode) {
                    setHasGeneratedCode(true)
                  }

                  // Only call onCodeGenerated if files have been saved
                  // If files haven't been saved yet, wait for files_saved event
                  if (filesSavedRef.current && onCodeGenerated) {
                    onCodeGenerated({ success: true })
                    doneReceivedRef.current = false
                    filesSavedRef.current = false
                  }

                  // Call auto-generate complete callback if this was an auto-generation
                  if (autoGeneratePrompt && onAutoGenerateComplete) {
                    onAutoGenerateComplete()
                  }
                  
                  // Clear input message after auto-generation completes
                  if (autoGeneratePrompt) {
                    setInputMessage("")
                  }
                  
                  // Reset message tracking
                  currentAssistantMessageRef.current = null
                  break
              }
            } catch (parseError) {
              console.error('Error parsing stream data:', parseError)
            }
          }
        }
      }

    } catch (error) {
      console.error("Error in streaming generation with URL:", error)
      const errorMessage = {
        role: "assistant",
        content: `I encountered an error: ${error.message}\n\nPlease try again or let me know if you need help with something else.`,
      }
      setMessages(prev => [...prev, errorMessage])
    } finally {
      setIsGenerating(false)
      currentAssistantMessageRef.current = null
      // Ensure any typing is cancelled on end/error
      setTypingCancelSignal((v) => v + 1)
      
      if (onGenerationEnd) {
        onGenerationEnd()
      }
    }
  }

  const handleSendMessage = async (e) => {
    e.preventDefault()
    if (!inputMessage.trim() || isGenerating) return

    const userMessage = {
      role: "user",
      content: inputMessage,
    }

    setMessages((prev) => [...prev, userMessage])
    const prompt = inputMessage
    setInputMessage("")
    
    // Use the same startGeneration function (false = manual generation)
    await startGeneration(prompt, false)
  }

  const handleUrlSubmit = async (data, userUrl, originalPrompt) => {
    setShowUrlPrompt(false)
    setUrlPromptData(null)

    // Continue generation with or without URL using the stored request info
    const requestInfo = currentRequestRef.current
    if (requestInfo) {
      // Preserve most recent URL selection for chained prompts (API, etc.)
      const skipScrapingSelection = userUrl === null
      lastUrlSelectionRef.current = {
        userUrl,
        skipScraping: skipScrapingSelection
      }
    }
    // Clear stored request info; follow-up prompts (like requires_api) will repopulate as needed
    currentRequestRef.current = null
    if (requestInfo) {
      if (userUrl === null) {
        // User chose to skip scraping; call streaming API with skipScraping=true
        console.log('ðŸš« [handleUrlSubmit] User skipped URL - checking analysisData')
        console.log('ðŸ“Š requestInfo.analysisData exists:', !!requestInfo.analysisData)
        if (requestInfo.analysisData) {
          console.log('âœ… Will pass analysis data to skip re-planning')
        } else {
          console.error('âŒ BUG: analysisData is missing! Planning will run twice.')
        }
        try {
          setIsGenerating(true)

          // Reset current assistant message tracking
          currentAssistantMessageRef.current = null
          explanationBufferRef.current = ""

          // Reset model thinking panel state for new stream
          setIsModelThinkingOpen(false)
          setModelThinkingFull("")
          setModelThinkingDisplay("")
          setIsGenerationComplete(false)
          thinkingTokensRef.current = []
          thinkingIdxRef.current = 0
          thinkingChunkCountRef.current = 0
          if (thinkingTimerRef.current) {
            clearTimeout(thinkingTimerRef.current)
            thinkingTimerRef.current = null
          }

          if (onGenerationStart) {
            onGenerationStart()
          }

          const requestPayload = {
            prompt: requestInfo.prompt,
            projectId: requestInfo.projectId,
            requestType: requestInfo.requestType,
            userProvidedUrl: null,
            skipScraping: true,
            // Use analysis data if available (for resuming after URL skip)
            ...(requestInfo.analysisData && {
              initialRequirementsAnalysis: requestInfo.analysisData.requirements,
              initialPlanningTokenUsage: requestInfo.analysisData.tokenUsage
            })
          }
          
          console.log('ðŸ“¤ [handleUrlSubmit Skip] Sending to API:', {
            skipScraping: true,
            hasInitialRequirementsAnalysis: !!requestPayload.initialRequirementsAnalysis,
            hasInitialPlanningTokenUsage: !!requestPayload.initialPlanningTokenUsage
          })

          const response = await fetch("/api/generate/stream", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify(requestPayload),
          })

          if (!response.ok) {
            // Check if it's a token limit error (403 with specific structure)
            if (response.status === 403) {
              try {
                const errorData = await response.json()
                if (errorData.details?.resourceType === 'tokens') {
                  // Show modal for token limit errors
                  setShowTokenLimitModal(true)
                  setIsGenerating(false)
                  if (onGenerationEnd) {
                    onGenerationEnd()
                  }
                  return
                }
              } catch (e) {
                // If we can't parse the response, fall through to generic error
              }
            }
            throw new Error(`HTTP error! status: ${response.status}`)
          }

          const reader = response.body.getReader()
          const decoder = new TextDecoder()
          let buffer = ""

          while (true) {
            const { done, value } = await reader.read()
            if (done) break

            buffer += decoder.decode(value, { stream: true })
            const lines = buffer.split('\n')
            buffer = lines.pop() || ""

            for (const line of lines) {
              if (line.startsWith('data: ')) {
                try {
                  const data = JSON.parse(line.slice(6))
                  switch (data.type) {
                    case "thinking_chunk":
                    case "thinking":
                      // Append Gemini thinking text to model thinking panel
                      if (typeof data.content === 'string' && data.content.length > 0) {
                        thinkingChunkCountRef.current += 1
                        setModelThinkingFull(prev => {
                          const newContent = prev + data.content
                          return newContent
                        })
                      }
                      break
                    case "start":
                      // show concise transition
                      setMessages(prev => [...prev, { role: "assistant", content: "Analysis complete, now generating your extension...\nContinuing with extension generation..." }])
                      break
                    case "planning_progress":
                      // Handle planning progress updates
                      if (data.phase && data.content) {
                        setCurrentPlanningPhase(data.phase)
                        setPlanningProgress(data.content)
                      }
                      break
                    case "explanation":
                      if (data.content) {
                        console.log('ðŸ“ [Skip flow] Buffering explanation chunk, length:', data.content.length, 'Preview:', data.content.substring(0, 100))
                        console.log('ðŸ“ [Skip flow] Current buffer length before adding:', explanationBufferRef.current.length)
                        explanationBufferRef.current += data.content
                        console.log('ðŸ“ [Skip flow] Current buffer length after adding:', explanationBufferRef.current.length)
                      }
                      break
                        case "usage_summary":
                          // Usage data is tracked server-side but not displayed to users
                          break
                        case "requires_api":
                          // Handle API requirement when scraping was skipped
                          currentRequestRef.current = {
                            prompt: requestInfo.prompt,
                            requestType: requestInfo.requestType,
                            projectId: requestInfo.projectId,
                            analysisData: data.analysisData
                          }
                          const apiModalDataSkip = {
                            data: {
                              suggestedAPIs: data.suggestedAPIs || [],
                              message: data.content || "This extension needs external API endpoints. Please configure them or choose to skip."
                            },
                            originalPrompt: requestInfo.prompt
                          }
                          // If onboarding is open, queue the modal
                          if (isOnboardingModalOpen) {
                            console.log('â³ Onboarding is open - queueing API prompt modal (skip scraping flow)')
                            setPendingApiPrompt(apiModalDataSkip)
                          } else {
                            console.log('âœ… Showing API prompt modal immediately (skip scraping flow)')
                            setApiPromptData(apiModalDataSkip)
                            setShowApiPrompt(true)
                          }
                          break
                    case "done":
                      // Mark that done was received
                      doneReceivedRef.current = true
                      
                      console.log('âœ… [Skip flow] Done signal received, explanation buffer length:', explanationBufferRef.current.length)
                      if (explanationBufferRef.current.trim()) {
                        const explanationContent = "Here's what I've built for you:\n\n" + explanationBufferRef.current.trim()
                        console.log('ðŸ“¤ [Skip flow] Adding explanation message to chat, full content preview:', explanationContent.substring(0, 150))
                        setMessages(prev => {
                          const newMessages = [...prev, { role: "assistant", content: explanationContent }]
                          console.log('ðŸ“Š [Skip flow] Messages array updated, total messages:', newMessages.length, 'Last message preview:', newMessages[newMessages.length - 1].content.substring(0, 100))
                          return newMessages
                        })
                        explanationBufferRef.current = ""
                      } else {
                        console.warn('âš ï¸ [Skip flow] Explanation buffer is empty!')
                      }
                      // Mark generation as complete to hide model thoughts
                      setIsGenerationComplete(true)
                      // Clear planning progress when generation is complete
                      setPlanningProgress(null)
                      setCurrentPlanningPhase(null)
                      if (!hasGeneratedCode) {
                        setHasGeneratedCode(true)
                      }
                      // Only call onCodeGenerated if files have been saved
                      // If files haven't been saved yet, wait for files_saved event
                      if (filesSavedRef.current && onCodeGenerated) {
                        onCodeGenerated({ success: true })
                        doneReceivedRef.current = false
                        filesSavedRef.current = false
                      }
                      break
                    default:
                      // ignore other noise
                      break
                  }
                } catch (e) {
                  console.error('Error parsing stream data (skipScraping):', e)
                }
              }
            }
          }
        } catch (err) {
          console.error('Error continuing generation without URL:', err)
          setMessages(prev => [...prev, { role: "assistant", content: `I encountered an error: ${err.message}` }])
        } finally {
          setIsGenerating(false)
          currentAssistantMessageRef.current = null
          // Ensure any typing is cancelled on end/error
          setTypingCancelSignal((v) => v + 1)
          if (onGenerationEnd) {
            onGenerationEnd()
          }
        }
      } else {
        await startGenerationWithUrl(requestInfo.prompt, userUrl, requestInfo.requestType, requestInfo.projectId, requestInfo.analysisData)
      }
    }
  }

  const handleUrlCancel = () => {
    setShowUrlPrompt(false)
    setUrlPromptData(null)
    setIsGenerating(false)
    currentAssistantMessageRef.current = null
    currentRequestRef.current = null
    lastUrlSelectionRef.current = null
  }

  const handleApiSubmit = async (data, userApis, originalPrompt) => {
    setShowApiPrompt(false)
    setApiPromptData(null)

    // Continue generation with APIs using the stored request info
    const requestInfo = currentRequestRef.current
    if (requestInfo) {
      try {
        setIsGenerating(true)

        // Reset tracking for new stream
        currentAssistantMessageRef.current = null
        explanationBufferRef.current = ""

        // Reset model thinking panel state for new stream
        setIsModelThinkingOpen(false)
        setModelThinkingFull("")
        setModelThinkingDisplay("")
        setIsGenerationComplete(false)
        thinkingTokensRef.current = []
        thinkingIdxRef.current = 0
        thinkingChunkCountRef.current = 0
        if (thinkingTimerRef.current) {
          clearTimeout(thinkingTimerRef.current)
          thinkingTimerRef.current = null
        }
        // Reset planning progress state
        setPlanningProgress(null)
        setCurrentPlanningPhase(null)
        // Reset file save tracking
        filesSavedRef.current = false
        doneReceivedRef.current = false

        if (onGenerationStart) {
          onGenerationStart()
        }

        const urlSelection = lastUrlSelectionRef.current
        const responsePayload = {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            prompt: requestInfo.prompt,
            projectId: requestInfo.projectId,
            requestType: requestInfo.requestType,
            userProvidedApis: userApis,
            ...(urlSelection ? {
              userProvidedUrl: urlSelection.skipScraping ? null : urlSelection.userUrl,
              skipScraping: !!urlSelection.skipScraping
            } : {}),
            // Use analysis data if available (for resuming after API prompt)
            ...(requestInfo.analysisData && {
              initialRequirementsAnalysis: requestInfo.analysisData.requirements,
              initialPlanningTokenUsage: requestInfo.analysisData.tokenUsage
            })
          }),
        }

        const response = await fetch("/api/generate/stream", responsePayload)

        if (!response.ok) {
          // Check if it's a token limit error (403 with specific structure)
          if (response.status === 403) {
            try {
              const errorData = await response.json()
              if (errorData.details?.resourceType === 'tokens') {
                // Show modal for token limit errors
                setShowTokenLimitModal(true)
                setIsGenerating(false)
                if (onGenerationEnd) {
                  onGenerationEnd()
                }
                return
              }
            } catch (e) {
              // If we can't parse the response, fall through to generic error
            }
          }
          throw new Error(`HTTP error! status: ${response.status}`)
        }

        const reader = response.body.getReader()
        const decoder = new TextDecoder()
        let buffer = ""

        // Helper function to add new assistant message
        const addNewAssistantMessage = (content) => {
          const newMessage = {
            role: "assistant",
            content: content
          }
          setMessages(prev => [...prev, newMessage])
        }

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ""

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              try {
                const chunk = JSON.parse(line.slice(6))

                // Handle different chunk types (same as startGeneration)
                switch (chunk.type) {
                  case "thinking_chunk":
                  case "thinking":
                    // Append Gemini thinking text to model thinking panel
                    if (typeof chunk.content === 'string' && chunk.content.length > 0) {
                      thinkingChunkCountRef.current += 1
                      setModelThinkingFull(prev => {
                        const newContent = prev + chunk.content
                        return newContent
                      })
                    }
                    break

                  case "planning_progress":
                    // Handle planning progress updates
                    if (chunk.phase && chunk.content) {
                      setCurrentPlanningPhase(chunk.phase)
                      setPlanningProgress(chunk.content)
                    }
                    break

                  case "start":
                    // Only add the start message if we haven't generated code yet
                    if (!hasGeneratedCode) {
                      addNewAssistantMessage("Starting to analyze your request...")
                    }
                    break

                  case "token_usage":
                    if (typeof chunk.total === 'number') {
                      setConversationTokenTotal(chunk.total)
                    }
                    break

                  case "usage_summary":
                    // Usage data is tracked server-side but not displayed to users
                    break

                  case "context_window":
                    addNewAssistantMessage('Context limit reached. Please start a new conversation.')
                    if (typeof chunk.total === 'number') {
                      setConversationTokenTotal(chunk.total)
                    }
                    break

                  case "response_id":
                    previousResponseIdRef.current = chunk.id
                    if (typeof chunk.tokensUsedThisRequest === 'number') {
                      const nextTotal = (conversationTokenTotal || 0) + chunk.tokensUsedThisRequest
                      setConversationTokenTotal(nextTotal)
                    }
                    break

                  // Ignore intermediate status noise
                  case "analyzing":
                  case "analysis_complete":
                  case "fetching_apis":
                  case "apis_ready":
                  case "scraping":
                  case "scraping_complete":
                  case "scraping_skipped":
                  case "context_ready":
                  case "generation_starting":
                    break

                  case "phase":
                    // Do not render phase updates to keep UI clean
                    break

                  case "explanation":
                    // Buffer explanation tokens; emit once on done
                    if (chunk.content) {
                      explanationBufferRef.current += chunk.content
                    }
                    break

                  case "generating_code":
                    break

                  case "code":
                    // If backend supplies file path info, auto-select in editor via global event
                    try {
                      const filePath = chunk.file_path || chunk.path || chunk.file || null
                      if (filePath && typeof window !== 'undefined') {
                        const evt = new CustomEvent('editor:selectFile', { detail: { file_path: String(filePath) } })
                        window.dispatchEvent(evt)
                      }
                    } catch (_) {}
                    break

                  case "files_saved":
                  case "generation_complete":
                    // Mark that files have been saved
                    filesSavedRef.current = true
                    // On save or completion, try to focus manifest.json after a short delay
                    try {
                      if (typeof window !== 'undefined') {
                        setTimeout(() => {
                          const evt = new CustomEvent('editor:focusManifest')
                          window.dispatchEvent(evt)
                        }, 200)
                      }
                    } catch (_) {}
                    // If done was already received, trigger onCodeGenerated now
                    if (doneReceivedRef.current && onCodeGenerated) {
                      onCodeGenerated({ success: true })
                      doneReceivedRef.current = false
                      filesSavedRef.current = false
                    }
                    break

                  case "error":
                    addNewAssistantMessage("I encountered an error: " + chunk.content + "\n\nPlease try again or let me know if you need help with something else.")
                    break

                  case "done":
                    // Mark that done was received
                    doneReceivedRef.current = true
                    
                    // Emit the final explanation once when stream completes
                    if (explanationBufferRef.current.trim()) {
                      addNewAssistantMessage("Here's what I've built for you:\n\n" + explanationBufferRef.current.trim())
                      explanationBufferRef.current = ""
                    }

                    // Mark generation as complete to hide model thoughts
                    setIsGenerationComplete(true)
                    // Clear planning progress when generation is complete
                    setPlanningProgress(null)
                    setCurrentPlanningPhase(null)

                    // Mark that code has been generated
                    if (!hasGeneratedCode) {
                      setHasGeneratedCode(true)
                    }

                    // Only call onCodeGenerated if files have been saved
                    // If files haven't been saved yet, wait for files_saved event
                    if (filesSavedRef.current && onCodeGenerated) {
                      onCodeGenerated({ success: true })
                      doneReceivedRef.current = false
                      filesSavedRef.current = false
                    }

                    // Reset message tracking
                    currentAssistantMessageRef.current = null
                    // Cancel any active typing and render full responses immediately
                    setTypingCancelSignal((v) => v + 1)
                    // Also request manifest focus
                    try {
                      if (typeof window !== 'undefined') {
                        const evt = new CustomEvent('editor:focusManifest')
                        window.dispatchEvent(evt)
                      }
                    } catch (_) {}
                    // Flush model thinking panel
                    setModelThinkingDisplay(modelThinkingFull)
                    if (thinkingTimerRef.current) {
                      clearTimeout(thinkingTimerRef.current)
                      thinkingTimerRef.current = null
                    }
                    break
                }
              } catch (parseError) {
                console.error('Error parsing stream data in API continuation:', parseError)
              }
            }
          }
        }

      } catch (error) {
        console.error('Error in API continuation:', error)
        const errorMessage = {
          role: "assistant",
          content: `I encountered an error while continuing generation: ${error.message}\n\nPlease try again.`
        }
        setMessages(prev => [...prev, errorMessage])
      } finally {
        setIsGenerating(false)
        currentAssistantMessageRef.current = null
        currentRequestRef.current = null
        // Ensure any typing is cancelled on end/error
        setTypingCancelSignal((v) => v + 1)

        if (onGenerationEnd) {
          onGenerationEnd()
        }
      }
    }
  }

  const handleApiCancel = () => {
    setShowApiPrompt(false)
    setApiPromptData(null)
    setIsGenerating(false)
    currentAssistantMessageRef.current = null
    currentRequestRef.current = null
  }

  return (
    <div className="flex flex-col h-full backdrop-blur-xl bg-black border border-white/10 rounded-2xl shadow-2xl overflow-hidden">
      {/* Chat Header */}
      <div className="p-4 border-b border-white/10 bg-black">
        <p className="text-sm text-gray-400">
          {projectName || "describe what you want to add or modify"}
        </p>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-hidden">
        <Conversation>
          <ConversationContent smooth={true} className="custom-scrollbar">
            {messages
              .filter((message) => !message.isThinking)
              .map((message, index) => (
                <ChatMessage key={index} message={message} index={index} typingCancelSignal={typingCancelSignal} />
              ))}
            
            {/* Show typing indicator when generating */}
            {isGenerating && (
              <ChatBubble variant="received">
                <ChatBubbleAvatar
                  src="/chromie-logo-1.png"
                  fallback="AI"
                  className="h-8 w-8 shrink-0"
                />
                <ChatBubbleMessage variant="received" isLoading />
              </ChatBubble>
            )}

          {/* Show planning progress when available */}
          {planningProgress && currentPlanningPhase && (
            <ChatBubble variant="received">
              <ChatBubbleAvatar
                src="/chromie-logo-1.png"
                fallback="AI"
                className="h-8 w-8 shrink-0"
              />
              <ChatBubbleMessage
                variant="received"
              >
                <div className="flex items-center space-x-3">
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-slate-400 rounded-full animate-pulse"></div>
                    <div className="w-2 h-2 bg-slate-300 rounded-full animate-pulse" style={{ animationDelay: '200ms' }}></div>
                    <div className="w-2 h-2 bg-slate-400 rounded-full animate-pulse" style={{ animationDelay: '400ms' }}></div>
                  </div>
                  <div className="flex flex-col">
                    <span className="text-xs text-slate-300 uppercase tracking-wide">
                      {currentPlanningPhase === 'analysis' && 'Planning'}
                      {currentPlanningPhase === 'documentation' && 'Documentation'}
                      {currentPlanningPhase === 'scraping' && 'Web Analysis'}
                      {!['analysis', 'documentation', 'scraping'].includes(currentPlanningPhase) && 'Planning'}
                    </span>
                    <span className="text-sm text-white font-medium">{planningProgress}</span>
                  </div>
                </div>
              </ChatBubbleMessage>
            </ChatBubble>
          )}
          
          {/* Collapsible Model Thinking Panel (Gemini) */}
          {(() => {
            const hasContent = !!(modelThinkingDisplay || modelThinkingFull)
            const forceShow = thinkingChunkCountRef.current > 0 // Force show if we have chunks
            const shouldShow = (hasContent || forceShow) && !isGenerationComplete
            return shouldShow
          })() && (
            <div className="mt-2">
              <button
                type="button"
                className="flex items-center justify-between w-full text-left text-xs uppercase tracking-wide text-slate-300 bg-slate-800/40 hover:bg-slate-800/60 border border-slate-600/40 px-3 py-2 rounded"
                onClick={() => setIsModelThinkingOpen(!isModelThinkingOpen)}
                aria-expanded={isModelThinkingOpen}
              >
                <span>Model thoughts ({thinkingChunkCountRef.current} chunks)</span>
                {isModelThinkingOpen ? <ChevronDown className="h-3 w-3" /> : <ChevronRight className="h-3 w-3" />}
              </button>
              {isModelThinkingOpen && (
                <div className="mt-2 p-3 rounded-lg border border-slate-500/20 bg-slate-800/20 text-white text-sm whitespace-pre-wrap leading-relaxed max-h-48 overflow-auto italic">
                  {modelThinkingDisplay || modelThinkingFull}
                </div>
              )}
            </div>
          )}

          {/* Open Button Card - Shows when code generation is complete and canvas is not open */}
          {effectiveHasGeneratedCode && onOpenCanvas && !isGenerating && !isCanvasOpen && (
            <ChatBubble variant="received">
              <ChatBubbleAvatar
                src="/chromie-logo-1.png"
                fallback="AI"
                className="h-8 w-8 shrink-0"
              />
              <ChatBubbleMessage
                variant="received"
              >
                <div className="flex items-center justify-between gap-4">
                  <div className="flex items-center gap-3 flex-1 min-w-0">
                    <div className="flex-shrink-0 w-8 h-8 rounded-lg bg-blue-600 flex items-center justify-center">
                      <FileCode className="h-4 w-4 text-white" />
                    </div>
                    <div className="flex-1 min-w-0">
                      <div className="text-sm font-medium text-white truncate">
                        {projectName || "Chrome Extension"}
                      </div>
                      <div className="text-xs text-slate-400">
                        Code generated successfully
                      </div>
                    </div>
                  </div>
                  <button
                    onClick={() => onOpenCanvas()}
                    className="flex-shrink-0 px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white text-sm font-medium rounded-lg transition-colors duration-200 shadow-md hover:shadow-lg"
                  >
                    Open
                  </button>
                </div>
              </ChatBubbleMessage>
            </ChatBubble>
          )}
          </ConversationContent>
          <ConversationScrollButton />
        </Conversation>
      </div>

      {/* Input */}
      <div className="border-t border-white/10 bg-black">
        <AIInputWithSearch
          placeholder={projectName ? `describe what you want to add or modify in ${projectName}...` : "describe what you want to add or modify..."}
          value={inputMessage}
          onChange={(value) => setInputMessage(value)}
          onSubmit={async (value, withSearch) => {
            if (!value.trim() || isGenerating) return

            const userMessage = {
              role: "user",
              content: value,
            }

            setMessages((prev) => [...prev, userMessage])
            const prompt = value
            setInputMessage("")
            
            // Use the same startGeneration function (false = manual generation)
            await startGeneration(prompt, false)
          }}
          disabled={isGenerating || !projectId}
          className="py-0"
        />
      </div>

      {/* URL Prompt Modal */}
      {showUrlPrompt && urlPromptData && (
        <ModalUrlPrompt
          data={urlPromptData.data}
          originalPrompt={urlPromptData.originalPrompt}
          onUrlSubmit={handleUrlSubmit}
          onCancel={handleUrlCancel}
          onCodeGenerated={onCodeGenerated}
          projectId={projectId}
          hasGeneratedCode={hasGeneratedCode}
          onGenerationEnd={onGenerationEnd}
        />
      )}

      {/* API Prompt Modal */}
      {showApiPrompt && apiPromptData && (
        <ModalApiPrompt
          data={apiPromptData.data}
          originalPrompt={apiPromptData.originalPrompt}
          onApiSubmit={handleApiSubmit}
          onCancel={handleApiCancel}
        />
      )}

      {/* Token Usage Alert Modal */}
      <TokenUsageAlert isOpen={showTokenLimitModal} onClose={() => setShowTokenLimitModal(false)} />
    </div>
  )
}
